{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TfIDF-PPMI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzO8+7PzcvOvg9U41Umnvb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muzakkialfarisi/MACHINE-LEARNING/blob/master/TfIDF_PPMI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv31EjmhZstb"
      },
      "source": [
        "**Import library python**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn_CBJDiKBEo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8de346c9-6361-439b-8f3c-45411e53612b"
      },
      "source": [
        "import nltk, re, pprint, random, string, heapq\n",
        "from nltk import word_tokenize # tokenisasi\n",
        "nltk.download('punkt') #\n",
        "import numpy as np # mengakses numpy\n",
        "import math # mengakses formula pada python\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/') # untuk dapat mengakses file / folder didalam drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zukgE2V7Z9dS"
      },
      "source": [
        "**Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ig-pqyK1hj"
      },
      "source": [
        "def set_corpus(artikel): # fungsi membuat corpus\n",
        "  corpus = nltk.sent_tokenize(artikel)\n",
        "  for i in range(len(corpus)):\n",
        "    corpus [i] = corpus [i].lower()\n",
        "    corpus [i] = re.sub(r'\\W',' ',corpus [i]) # menghapus tanda baca\n",
        "    corpus [i] = re.sub(r'\\s+',' ',corpus [i]) # menghapus spasi berlebih\n",
        "  return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnS7rTx6aEkW"
      },
      "source": [
        "**Hitung Frequensi**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-EQ68h4Vn1M"
      },
      "source": [
        "def hitfreq(corpus): # fungsi menhitung frequensi dengan parameter crpus\n",
        "  wordfreq = {}\n",
        "  for sentence in corpus:\n",
        "      tokens = nltk.word_tokenize(sentence)\n",
        "      for token in tokens:\n",
        "          if token not in wordfreq.keys():\n",
        "              wordfreq[token] = 1\n",
        "          else:\n",
        "              wordfreq[token] += 1\n",
        "  return wordfreq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGzZ2j-xfQGd"
      },
      "source": [
        "**TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRm1zXVhcPvk"
      },
      "source": [
        "def mostfreq(wordfreq): # fungsi untuk set hitung frequensi maksimum\n",
        "  most_freq = heapq.nlargest(100, wordfreq, key=wordfreq.get) # setting wordfreq bisa diubah sesuai dengan karakteristik data yang digunakan.\n",
        "  return most_freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsgFTsNmDugk"
      },
      "source": [
        "def idf_value(corpus): # fungsi menghitung nilai idf\n",
        "  most_freq = mostfreq(hitfreq(corpus)) # memanggil fungsi set frequensi maksimum dengan parameter fungsi mengitung frequensi\n",
        "  word_idf_values = {}\n",
        "  for token in most_freq:\n",
        "      doc_containing_word = 0\n",
        "      for document in corpus:\n",
        "          if token in nltk.word_tokenize(document):\n",
        "              doc_containing_word += 1\n",
        "      word_idf_values[token] = np.log10(len(corpus)/(doc_containing_word))\n",
        "  return word_idf_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo_cjZqbE2d3"
      },
      "source": [
        "def tf_value(corpus): # fungsi mengitung nilai tf\n",
        "  most_freq = mostfreq(hitfreq(corpus)) # memanggil fungsi set frequensi maksimum dengan parameter fungsi mengitung frequensi\n",
        "  word_tf_values = {}\n",
        "  for token in most_freq:\n",
        "      sent_tf_vector = []\n",
        "      for document in corpus:\n",
        "          doc_freq = 0\n",
        "          for word in nltk.word_tokenize(document):\n",
        "              if token == word:\n",
        "                    doc_freq += 1\n",
        "          # word_tf = doc_freq # tanpa normalisasi\n",
        "          word_tf = doc_freq/len(nltk.word_tokenize(document)) # normalisasi dengan panjang dokumen\n",
        "          sent_tf_vector.append(word_tf)\n",
        "      word_tf_values[token] = sent_tf_vector\n",
        "  return word_tf_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SscZ_rETH-Te"
      },
      "source": [
        " def tfidf_value(corpus): # fungsi mengitung nilai tfidf\n",
        "  word_tf_values = tf_value(corpus) # memanggil fungsi menghitung nilai tf\n",
        "  word_idf_values = idf_value(corpus) # memanggil fungsi menghitung nilai idf\n",
        "  tfidf_values = []\n",
        "  for token in word_tf_values.keys():\n",
        "      tfidf_sentences = [] # 1 dokumen adalah 1 kalimat\n",
        "      for tf_sentence in word_tf_values[token]:\n",
        "          tf_idf_score = tf_sentence * word_idf_values[token]\n",
        "          tfidf_sentences.append(tf_idf_score)\n",
        "      tfidf_values.append(tfidf_sentences)\n",
        "  return tfidf_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2JssXqrpoHn"
      },
      "source": [
        "def not_0_tfidf(tfidf_values): # fungsi mencari nilai tidak sama dengan 0 dengan parameter return nilai tfidf\n",
        "  pembilang = 0 \n",
        "  penyebut = 0\n",
        "  for i in range(len(tfidf_values)):\n",
        "    for j in tfidf_values[i]:\n",
        "      if j != 0:\n",
        "        pembilang += 1\n",
        "      else:\n",
        "        pembilang = pembilang\n",
        "      penyebut += 1\n",
        "  return pembilang/penyebut*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03R9_JVHUkCi"
      },
      "source": [
        "def cosine_similarity_sama(tfidf_values, x, y): # fungsi menghitung cosine_similarity kalimat dengan topik yang sama\n",
        "  tf_idf_model = np.asarray(tfidf_values)\n",
        "  tf_idf_model = np.transpose(tf_idf_model)\n",
        "  if (x < len(tf_idf_model) and y < len(tf_idf_model)):\n",
        "    return np.dot(tf_idf_model[x],tf_idf_model[y])/np.linalg.norm(tf_idf_model[x])*np.linalg.norm(tf_idf_model[y])\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCGdVCe3BWvS"
      },
      "source": [
        "def cosine_similarity_beda(tfidf_values1, tfidf_values2, x, y): # fungsi menghitung cosine_similarity kalimat dengan topik yang berbeda\n",
        "  tf_idf_model1 = np.asarray(tfidf_values1)\n",
        "  tf_idf_model1 = np.transpose(tf_idf_model1)\n",
        "  tf_idf_model2 = np.asarray(tfidf_values2)\n",
        "  tf_idf_model2 = np.transpose(tf_idf_model2)\n",
        "  return np.dot(tf_idf_model1[x],tf_idf_model2[y])/np.linalg.norm(tf_idf_model1[x])*np.linalg.norm(tf_idf_model2[y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wAv2p0hfvCO"
      },
      "source": [
        "def kata_cosine_similarity_sama(tfidf_values, x, y): # fungsi menghitung cosine_similarity kata dengan topik yang sama\n",
        "  tf_idf_model = np.asarray(tfidf_values)\n",
        "  if (x < len(tf_idf_model) and y < len(tf_idf_model)):\n",
        "    return np.dot(tf_idf_model[x],tf_idf_model[y])/np.linalg.norm(tf_idf_model[x])*np.linalg.norm(tf_idf_model[y])\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myO-T1CxgvUh"
      },
      "source": [
        "def kata_cosine_similarity_beda(tfidf_values1, tfidf_values2, x, y): # fungsi menghitung cosine_similarity kata dengan topik yang berbeda\n",
        "  # karena ordonya berbeda, maka samakan ordo dgn meng sign angka 0 pada new pixel\n",
        "  if len(tfidf_values1[0]) < len(tfidf_values2[0]):\n",
        "    baru = tfidf_values1\n",
        "    for i in range(len(tfidf_values1)):\n",
        "      for j in range(len(tfidf_values2[i])-len(tfidf_values1[i])):\n",
        "        baru[i].append(0)\n",
        "    tf_idf_model1 = np.asarray(baru)\n",
        "    tf_idf_model2 = np.asarray(tfidf_values2)\n",
        "  else:\n",
        "    baru = tfidf_values2\n",
        "    for i in range(len(tfidf_values1)):\n",
        "      for j in range(len(tfidf_values1[i])-len(tfidf_values2[i])):\n",
        "        baru[i].append(0)\n",
        "    tf_idf_model1 = np.asarray(tfidf_values1)\n",
        "    tf_idf_model2 = np.asarray(baru)\n",
        "  \n",
        "  return np.dot(tf_idf_model1[x],tf_idf_model2[y])/np.linalg.norm(tf_idf_model1[x])*np.linalg.norm(tf_idf_model2[y])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lztYhzcATqP"
      },
      "source": [
        "**PPMI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4NopuWsCgwl"
      },
      "source": [
        "# inisialisasi matriks co-occurrence\n",
        "def initial_matriks_co(vocab_freq):\n",
        "  co_occurrence_mat = {}\n",
        "  for token_1 in vocab_freq.keys():\n",
        "    co_occurrence_terms = []\n",
        "    for token_2 in vocab_freq.keys():\n",
        "      co_occurrence_mat[(token_1,token_2)] = 0\n",
        "  return co_occurrence_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2HpBx2KajP7"
      },
      "source": [
        "def proses_matriks_co(corpus, co_occurrence_mat):\n",
        "  window_size = 2 # contoh, ukuran window = 2\n",
        "  # proses\n",
        "  for sentence in corpus:\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    for i in range(0,len(tokens)):\n",
        "      # konteks kata-kata sebelah kiri\n",
        "      left_index = i-1\n",
        "      while left_index >= 0 and left_index >= i-window_size:\n",
        "        token_1 = tokens[i]\n",
        "        token_2 = tokens[left_index]\n",
        "        co_occurrence_mat[(token_1,token_2)] += 1\n",
        "        left_index = left_index - 1\n",
        "      # konteks kata-kata sebelah kanan\n",
        "      right_index = i+1\n",
        "      while right_index < len(tokens) and right_index <= i+window_size:\n",
        "        token_1 = tokens[i]\n",
        "        token_2 = tokens[right_index] \n",
        "        co_occurrence_mat[(token_1,token_2)] += 1    \n",
        "        right_index = right_index + 1\n",
        "  return co_occurrence_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHHSblAEcDn7"
      },
      "source": [
        "def cooccurrence_mat(wordfreq, co_occurrence_mat):\n",
        "  bigram_count = {}\n",
        "  str_token = '\\t'\n",
        "  for token in wordfreq.keys():\n",
        "    str_token += '\\t\\t'+token\n",
        "  for token_1 in wordfreq.keys():\n",
        "    str_row = token_1+'\\t'\n",
        "    curr_bigram_count = 0\n",
        "    bigram_count[token_1] = 0\n",
        "    for token_2 in wordfreq.keys():\n",
        "      str_row += '\\t\\t'+str(co_occurrence_mat[(token_1,token_2)])\n",
        "      curr_bigram_count += co_occurrence_mat[(token_1,token_2)] # update jumlah kemunculan term\n",
        "    bigram_count[token_1] = curr_bigram_count # assignemnt jumlah kemunculan term sebagai bagian dari bigram\n",
        "  return bigram_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNz67Olqd8-8"
      },
      "source": [
        "def prob_term(wordfreq, co_occurrence_mat):\n",
        "  term_context_prob = {}\n",
        "  sum_term_context = sum(co_occurrence_mat[item] for item in co_occurrence_mat)\n",
        "  for token_1 in wordfreq.keys():\n",
        "    for token_2 in wordfreq.keys():    \n",
        "      term_context_prob[(token_1,token_2)] = co_occurrence_mat[(token_1,token_2)]/sum_term_context\n",
        "  return term_context_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPWkAtLee7yy"
      },
      "source": [
        "def pmi(wordfreq, co_occurrence_mat, bigram_count, term_context_prob):\n",
        "  pmi_mat = {}\n",
        "  sum_term_context = sum(co_occurrence_mat[item] for item in co_occurrence_mat)\n",
        "  for token_1 in wordfreq.keys():\n",
        "    for token_2 in wordfreq.keys(): \n",
        "      token_1_prob = bigram_count[token_1]/sum_term_context\n",
        "      token_2_prob = bigram_count[token_2]/sum_term_context\n",
        "      if term_context_prob[(token_1,token_2)] > 0:\n",
        "        pmi_mat[(token_1,token_2)] = round(math.log2(term_context_prob[(token_1,token_2)]/(token_1_prob*token_2_prob)), 4)\n",
        "      else: # kalau nilai probability = 0, tidak bisa dihitung log 2 -nya\n",
        "        pmi_mat[(token_1,token_2)] = None\n",
        "  return pmi_mat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bfEYJuUh13s"
      },
      "source": [
        "def not_0_ppmi(wordfreq, pmi_mat):\n",
        "  pembilang = 0\n",
        "  penyebut = 0\n",
        "  for token_1 in wordfreq.keys():\n",
        "    for token_2 in wordfreq.keys():\n",
        "      if pmi_mat[(token_1,token_2)] is None or pmi_mat[(token_1,token_2)] > 0:\n",
        "        pembilang += 1\n",
        "      penyebut += 1\n",
        "  return (pembilang/penyebut*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48DWwa5WfUDE"
      },
      "source": [
        "**MAIN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQhK68X4pjF8"
      },
      "source": [
        "t_1 = open('/content/drive/My Drive/Colab Notebooks/DataTrain/a1.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a2.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a3.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a4.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a5.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a6.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a7.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a8.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a9.txt').read()\n",
        "t_1 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/a10.txt').read()\n",
        "t_2 = open('/content/drive/My Drive/Colab Notebooks/DataTrain/b1.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b2.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b3.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b4.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b5.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b6.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b7.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b8.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b9.txt').read()\n",
        "t_2 += open('/content/drive/My Drive/Colab Notebooks/DataTrain/b10.txt').read()\n",
        "article = t_1 + t_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWg4d_QXGJu_"
      },
      "source": [
        "corpus1 = set_corpus(t_1) # fungsi pembuatan corpus dengan topik A\n",
        "wordfreq1 = hitfreq(corpus1) # fungsi hitung frequensi corpus topik A\n",
        "\n",
        "corpus2 = set_corpus(t_2) # fungsi pembuatan corpus dengan topik B\n",
        "wordfreq2 = hitfreq(corpus2) # fungsi hitung frequensi corpus topik B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTs4xkjMixr-"
      },
      "source": [
        "**PPMI**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZb9g03oGPJq"
      },
      "source": [
        "# Topik A\n",
        "co_occurrence_mat1 = initial_matriks_co(wordfreq1)\n",
        "co_occurrence_mat1 = proses_matriks_co(corpus1, co_occurrence_mat1)\n",
        "bigram_count1 = cooccurrence_mat(wordfreq1, co_occurrence_mat1)\n",
        "term_context_prob1 = prob_term(wordfreq1, co_occurrence_mat1)\n",
        "pmi_mat1 = pmi(wordfreq1, co_occurrence_mat1, bigram_count1, term_context_prob1)\n",
        "\n",
        "# Topik B\n",
        "co_occurrence_mat2 = initial_matriks_co(wordfreq2)\n",
        "co_occurrence_mat2 = proses_matriks_co(corpus2, co_occurrence_mat2)\n",
        "bigram_count2 = cooccurrence_mat(wordfreq2, co_occurrence_mat2)\n",
        "term_context_prob2 = prob_term(wordfreq2, co_occurrence_mat2)\n",
        "pmi_mat2 = pmi(wordfreq2, co_occurrence_mat2, bigram_count2, term_context_prob2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7N9qWzRsKi0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c7252c20-562e-48a5-90fb-9ded7fc6858c"
      },
      "source": [
        "print('Elemen tidak sama dengan nol PPMI')\n",
        "print('Topik A :',not_0_ppmi(wordfreq1, pmi_mat1),'%')\n",
        "print('Topik B :',not_0_ppmi(wordfreq2, pmi_mat2),'% ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elemen tidak sama dengan nol PPMI\n",
            "Topik A : 99.98659279778394 %\n",
            "Topik B : 99.9952844959384 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V79Loriuio_G"
      },
      "source": [
        "**TF-IDF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvwVae56xRxa"
      },
      "source": [
        "# Topik A\n",
        "word_idf_values1 = idf_value(corpus1)\n",
        "word_tf_values1 = tf_value(corpus1)\n",
        "tfidf_values1 = tfidf_value(corpus1)\n",
        "not_0_1 = not_0_tfidf(tfidf_values1)\n",
        "\n",
        "# Topik B\n",
        "word_idf_values2 = idf_value(corpus2)\n",
        "word_tf_values2 = tf_value(corpus2)\n",
        "tfidf_values2 = tfidf_value(corpus2)\n",
        "not_0_2 = not_0_tfidf(tfidf_values2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdyhM5EiExby",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "31a1d7f9-c360-4834-a1ff-a1cc6bf828a1"
      },
      "source": [
        "print('Elemen tidak sama dengan nol TF-IDF')\n",
        "print('Topik-A   :',not_0_1,'%')\n",
        "print('Topik-B   :',not_0_2,'%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elemen tidak sama dengan nol TF-IDF\n",
            "Topik-A   : 9.097222222222221 %\n",
            "Topik-B   : 7.1878787878787875 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1G9JHYa23ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ece73829-d9a5-4ded-e6ae-53f6db19f7c2"
      },
      "source": [
        "print('Cosine Similarity kata dengan topik yang sama')\n",
        "print('Topik A dengan panjang 0 sampai dengan',len(tfidf_values1[0])-1)\n",
        "kal_a_1 = 10\n",
        "kal_a_2 = 7\n",
        "print('- Kalimat 10 dan 7 :',cosine_similarity_sama(tfidf_values1,kal_a_1,kal_a_2))\n",
        "print('Topik B dengan panjang 0 sampai dengan',len(tfidf_values2[0])-1)\n",
        "kal_b_1 = 10\n",
        "kal_b_2 = 7\n",
        "print('- Kalimat 10 dan 7 :',cosine_similarity_sama(tfidf_values2,kal_b_1,kal_b_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity kata dengan topik yang sama\n",
            "Topik A dengan panjang 0 sampai dengan 143\n",
            "- Kalimat 10 dan 7 : 0.005213896668408891\n",
            "Topik B dengan panjang 0 sampai dengan 164\n",
            "- Kalimat 10 dan 7 : 0.02523579819493903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I946IhoHJMp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d60f14a0-d771-4767-e2b6-c48b0a6845dd"
      },
      "source": [
        "print('Cosine Similarity kalimat dengan topik yang berbeda')\n",
        "print('Topik A dengan panjang kalimat 0 sampai dengan',len(tfidf_values1[0])-1) \n",
        "print('Topik B dengan panjang kalimat 0 sampai dengan',len(tfidf_values2[0])-1)\n",
        "kal_topik_a = 10\n",
        "kal_topik_b = 7\n",
        "print('- Topik A Kalimat-10 dan Topik B kalimat-7:',cosine_similarity_beda(tfidf_values1,tfidf_values2,kal_topik_a,kal_topik_b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity kalimat dengan topik yang berbeda\n",
            "Topik A dengan panjang kalimat 0 sampai dengan 143\n",
            "Topik B dengan panjang kalimat 0 sampai dengan 164\n",
            "- Topik A Kalimat-10 dan Topik B kalimat-7: 0.0019532851562571734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0K_ad477Dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "90e1dbdc-5290-4568-c68e-5c3ea3554714"
      },
      "source": [
        "print('Cosine Similarity kata dengan topik yang sama')\n",
        "print('Topik A dengan panjang 0 sampai dengan',len(tfidf_values1)-1)\n",
        "kal_a_1 = 6\n",
        "kal_a_2 = 4\n",
        "print('- kata 0 dan 2 :',kata_cosine_similarity_sama(tfidf_values1,kal_a_1,kal_a_2))\n",
        "print('Topik B dengan panjang 0 sampai dengan',len(tfidf_values2)-1)\n",
        "kal_b_1 = 6\n",
        "kal_b_2 = 4\n",
        "print('- kata 2 dan 0 :',kata_cosine_similarity_sama(tfidf_values2,kal_b_1,kal_b_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity kata dengan topik yang sama\n",
            "Topik A dengan panjang 0 sampai dengan 99\n",
            "- kata 0 dan 2 : 0.008678264583141861\n",
            "Topik B dengan panjang 0 sampai dengan 99\n",
            "- kata 2 dan 0 : 0.0036073884440326392\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NxNccvHgskH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "658bbe82-de76-4e3a-ccde-a96d237f2e26"
      },
      "source": [
        "print('Cosine Similarity kata dengan topik yang beda')\n",
        "print('Topik A dengan panjang kalimat 0 sampai dengan',len(tfidf_values1)-1) \n",
        "print('Topik B dengan panjang kalimat 0 sampai dengan',len(tfidf_values2)-1)\n",
        "kata_topik_a = 6\n",
        "kata_topik_b = 4\n",
        "print('- Topik A kata-6 dan Topik B kata-4:',kata_cosine_similarity_beda(tfidf_values1,tfidf_values2,kata_topik_a,kata_topik_b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity kata dengan topik yang beda\n",
            "Topik A dengan panjang kalimat 0 sampai dengan 99\n",
            "Topik B dengan panjang kalimat 0 sampai dengan 99\n",
            "- Topik A kata-6 dan Topik B kata-4: 0.0038319178720998804\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}